{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b459722-fa79-4fa0-aee1-834e642577e5",
   "metadata": {},
   "source": [
    "## <b>Weather forecast project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48cdcce-4a78-4235-a3fa-fa507d893731",
   "metadata": {},
   "source": [
    "# <b>04 - OPTIMISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723f516-ee9d-4db3-8b4e-3497ffd5887a",
   "metadata": {},
   "source": [
    "### Packages nécessaires au notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3e0aa-fffd-4c11-adc6-51c65dac58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bokeh\n",
    "import plotly\n",
    "import sys\n",
    "import geopy.distance\n",
    "from collections import defaultdict\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from math import radians\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle\n",
    "import time\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, validation_curve\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression,f_classif,chi2\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, cohen_kappa_score, ConfusionMatrixDisplay, roc_curve, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer, classification_report, make_scorer, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, classification_report, make_scorer, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e885ef-d072-4786-9d88-2442e103d03a",
   "metadata": {},
   "source": [
    "###### <b>Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc4c9d-80ab-4cce-976d-bcde5298bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_features.csv\").iloc[:,2:] #iloc en attendant de corriger le notebook3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6bb257-1be9-4816-b3f0-1f246ba5e4cf",
   "metadata": {},
   "source": [
    "###### <b>Séparation des données en variables explicatives et variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20be86-d5cd-40a0-b56c-749febe9aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['raintomorrow'],axis=1)\n",
    "y = df['raintomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d19684-a43c-4555-8afe-df2cd8f60ddb",
   "metadata": {},
   "source": [
    "###### <b>Fractionnement des données en ensemble d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369931f-0420-41a2-a332-a66b3256b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d66522-7273-4d50-b914-ba4e4b86d1ff",
   "metadata": {},
   "source": [
    "###### <b> Définition des fonctions pour lancer les modèles et afficher la courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a23ce-795f-4f49-be82-1f37790bb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train, y_train, X_test, y_test, verbose=True):\n",
    "    t0=time.time()\n",
    "    if verbose == False:\n",
    "        model.fit(X_train,y_train, verbose=0)\n",
    "    else:\n",
    "        model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred) \n",
    "    coh_kap = cohen_kappa_score(y_test, y_pred)\n",
    "    time_taken = time.time()-t0\n",
    "    print(\"Accuracy = {}\".format(accuracy))\n",
    "    print(\"ROC Area under Curve = {}\".format(roc_auc))\n",
    "    print(\"Cohen's Kappa = {}\".format(coh_kap))\n",
    "    print(\"Time taken = {}\".format(time_taken))\n",
    "    print(classification_report(y_test,y_pred,digits=5))\n",
    "    \n",
    "    probs = model.predict_proba(X_test)  \n",
    "    probs = probs[:, 1]  \n",
    "    fper, tper, thresholds = roc_curve(y_test, probs) \n",
    "    plot_roc_cur(fper, tper)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, predictions, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return model, accuracy, roc_auc, coh_kap, time_taken\n",
    "\n",
    "def plot_roc_cur(fper, tper):  \n",
    "    plt.plot(fper, tper, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d125b-2dc8-4b1c-9f5c-7109085d5294",
   "metadata": {},
   "source": [
    "## 1) eXtreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70dfb7-822a-4de4-8519-d41b1f21b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "test = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da126d-c548-4550-84aa-7bfc0e0c7aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'booster': 'gbtree', 'learning_rate': 0.1, 'objective': 'binary:logistic','early_stopping_rounds': 20}\n",
    "\n",
    "xgb = xgb.train(params=params, dtrain=train, num_boost_round=10000, evals=[(train, 'train'), (test, 'eval')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1953f94-7b39-47c2-b5d8-bdef7327d4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(objective='binary:logistic')\n",
    "xgbc.fit(X_train,y_train)\n",
    "predicted = xgbc.predict(X_test)\n",
    "print (\"The accuracy of Logistic Regression is : \", accuracy_score(y_test, predicted)*100, \"%\")\n",
    "print()\n",
    "print(\"F1 score for XGBoost is :\",f1_score(y_test, predicted,)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4a9bb-8294-435b-9e61-562e446d95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb ={'n_estimators': 500,\n",
    "            'max_depth': 16}\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(**params_xgb)\n",
    "model_xgb, accuracy_xgb, roc_auc_xgb, coh_kap_xgb, tt_xgb = run_model(model_xgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92680e3b-eaae-4f68-b19a-fb7ad6e9b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(15, 20),\n",
    "    'n_estimators':range(500, 1500,100)\n",
    "}\n",
    "clf = xgb.XGBClassifier(eta = 0.1)\n",
    "randomized_clf = RandomizedSearchCV(estimator=clf,param_distributions=param_grid,scoring = 'accuracy',n_iter = 7, cv = 3, random_state = 42)\n",
    "randomized_clf.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best parameters: \", randomized_clf.best_params_)\n",
    "print(\"Best Score: \", randomized_clf.best_score_)\n",
    "features = pd.DataFrame(randomized_clf.best_estimator_.feature_importances_,index = X_train.columns)\n",
    "features.sort_values(by = 0, ascending = True, inplace = True)\n",
    "plt.figure(figsize=(20,15))\n",
    "features.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29150d3-351b-4c3f-9cb3-c8a282659e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randomized_clf.best_estimator_.predict(X_test)\n",
    "plot_confusion_matrix(randomized_clf.best_estimator_, X_test, y_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#Best parameters:  {'n_estimators': 1400, 'max_depth': 18}\n",
    "#Best Score:  0.8672673172800799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ece9b4-b2fa-4903-a882-8156c51c33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: \", randomized_clf.best_params_)\n",
    "print(\"Best Score: \", randomized_clf.best_score_)\n",
    "features = pd.DataFrame(randomized_clf.best_estimator_.feature_importances_,index = X_train.columns)\n",
    "features.sort_values(by = 0, ascending = True, inplace = True)\n",
    "plt.figure(figsize=(20,15))\n",
    "features.plot(kind = 'barh')\n",
    "\n",
    "y_pred = randomized_clf.best_estimator_.predict(X_test)\n",
    "plot_confusion_matrix(randomized_clf.best_estimator_, X_test, y_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932352cb-2f0f-4e71-adf2-e5ad763086ff",
   "metadata": {},
   "source": [
    "### 2) LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a1004-fdba-4aba-9366-7c7be1325440",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_train, y_train, X_test , y_test in zip([X_train],[y_train],[X_test],[y_test]): #la boucle est conservée si jamais on souhaite ajouter un autre dataset tel que pca...\n",
    "    logistic_params  = {\n",
    "        \"solver\" : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        \"penalty\" : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "        'C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "        \"class_weight\" :['balanced', None]\n",
    "    }\n",
    "\n",
    "    # apply gridsearch model \n",
    "    lr_grid = GridSearchCV(LogisticRegression(), logistic_params, scoring = 'accuracy',cv = 4)\n",
    "\n",
    "    lr_grid.fit(X_train, y_train)\n",
    "    lr_grid.best_estimator_\n",
    "    y_pred = lr_grid.predict(X_test)\n",
    "\n",
    "    best_score = lr_grid.best_score_\n",
    "    best_params = lr_grid.best_params_\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy =: {round(lr_grid.score(X_train, y_train) * 100, 2)}%')\n",
    "    print(f'Accuracy =: {round(lr_grid.score(X_test, y_test) * 100, 2)}%')\n",
    "    print ('--')\n",
    "    print ('Best Parameters is', best_params)\n",
    "    print ('--')\n",
    "    print ('ROC Score is', roc)\n",
    "    print ('--')\n",
    "    print ('Recall Score is ', recall)\n",
    "    print ('--')\n",
    "    print ('Confusion Matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeaeda1-7568-4d2b-9937-45b3aa63b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Création et entraînement d'un modèle de régression logistique\n",
    "logreg_clf = LogisticRegression(solver='lbfgs')\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des probabilités des classes pour les données de test\n",
    "probs_logreg = logreg_clf.predict_proba(X_test)\n",
    "\n",
    "# Calcul des taux de faux positifs, des taux de vrais positifs et des seuils correspondants\n",
    "fpr_logreg, tpr_logreg, seuils_logreg = roc_curve(y_test,probs_logreg[:,1],pos_label=1)\n",
    "\n",
    "# Calcul de l'aire sous la courbe ROC\n",
    "roc_auc_logreg = auc(fpr_logreg, tpr_logreg)\n",
    "\n",
    "# Tracé de la courbe ROC\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(fpr_logreg, tpr_logreg, color='blue', lw=2, label='Logistic Regression (auc = %0.2f)' % roc_auc_logreg)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Aléatoire (auc = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Score sur les données de test\n",
    "score_logreg = logreg_clf.score(X_test, y_test)\n",
    "print(\"Le score du modèle de régression logistique sur les données de test est : {:.2f}\".format(score_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675f236-afcb-4950-b3bf-a4285c5fe3fa",
   "metadata": {},
   "source": [
    "### 3) Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202f5b1-4c70-4351-984c-3f60addf41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_train, y_train, X_test , y_test in zip([X_train],[y_train],[X_test],[y_test]): #la boucle est conservée si jamais on souhaite ajouter un autre dataset tel que pca...\n",
    "\n",
    "    tree_params  = {\n",
    "    \"criterion\" : ['gini', 'entropy', 'log_loss'],\n",
    "    \"max_depth\" : [40,100, None],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'max_features' : [\"auto\",'sqrt', 'log2',None],\n",
    "    'random_state' : [4,5],\n",
    "    'max_leaf_nodes' : [5,10,None],\n",
    "    'class_weight': ['balanced',None]\n",
    "    }\n",
    "\n",
    "    # apply gridsearch model \n",
    "    tree_grid = GridSearchCV(DecisionTreeClassifier(), tree_params, scoring = 'accuracy',cv = 4)\n",
    "\n",
    "    tree_grid.fit(X_train, y_train)\n",
    "    tree_grid.best_estimator_\n",
    "    y_pred = tree_grid.predict(X_test)\n",
    "\n",
    "    best_score = tree_grid.best_score_\n",
    "    best_params = tree_grid.best_params_\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy =: {round(tree_grid.score(X_train, y_train) * 100, 2)}%')\n",
    "    print(f'Accuracy =: {round(tree_grid.score(X_test, y_test) * 100, 2)}%')\n",
    "\n",
    "    print ('--')\n",
    "    print ('Best Parameters is', best_params)\n",
    "    print ('--')\n",
    "    print ('ROC Score is', roc)\n",
    "    print ('--')\n",
    "    print ('Recall Score is ', recall)\n",
    "    print ('--')\n",
    "    print ('Confusion Matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c76856-91f0-4896-8ebe-58fea788357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grille de recherche pour avoir les meilleurs hyperparametres pour le criterion et max_depth.\n",
    "\n",
    "param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 15),'min_samples_split':[300],'min_samples_leaf':[100]}\n",
    "nfolds = 3\n",
    "\n",
    "resc_dt = make_scorer(f1_score,pos_label=1)\n",
    "\n",
    "# decision tree model\n",
    "dtree_model=DecisionTreeClassifier()\n",
    "#use gridsearch to test all values\n",
    "dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=nfolds, scoring=resc_dt)\n",
    "#fit model to data\n",
    "dtree_gscv.fit(X_train, y_train)\n",
    "\n",
    "dtree_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3c6d1-3ef3-4131-8fba-1c15a505b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de l'arbre avec les meilleurs hyperparametres calcules ci dessus\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion='gini', max_depth=7,random_state=123,)\n",
    "dt_clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a38b02-bd2e-4110-9855-d2ab6e097dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "## Méthode 2 : à l'aide de pandas\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49483335-8e75-46b1-b6de-3782647abf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cette commande permet de tracer et d'évaluer graphiquement la performance d'un modèle de classification binaire, en comparant la courbe ROC du modèle avec celle d'un modèle de classification aléatoire.\n",
    "# La courbe ROC est utile pour évaluer la performance globale du modèle et pour choisir le seuil de probabilité optimal pour la classification binaire.\n",
    "\n",
    "probs_dt = dt_clf.predict_proba(X_test)\n",
    "\n",
    "fpr_dt, tpr_dt, seuils_dt = roc_curve(y_test,probs_dt[:,1],pos_label=1)\n",
    "#fpr1, tpr1, seuils1 = det_curve(y_test,probs[:,1],pos_label=1)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(fpr_dt, tpr_dt, color='purple', lw=2, label='Decision Tree (auc = %0.2f)' % roc_auc_dt)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Aléatoire (auc = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d0046-762d-4e8b-a90c-c70fa4cf21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AdaBoostClassifier(base_estimator=dt_clf,n_estimators=400)\n",
    "ac.fit(X_train , y_train)\n",
    "ac.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4c4ac-9bb7-47e2-a2fe-d358dac97095",
   "metadata": {},
   "source": [
    "/!\\ à corriger pour relancer la cellule\n",
    "probs_ada = ac.predict_proba(X_test)\n",
    "\n",
    "fpr_ada, tpr_ada, seuils_ada = roc_curve(y_test,probs_ada[:,1],pos_label=1)\n",
    "roc_auc_ada = auc(fpr_ada, tpr_ada)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(fpr_ada, tpr_ada, color='purple', lw=2, label='Ada Boost Classifier (auc = %0.2f)' % roc_auc_ada)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Aléatoire (auc = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3c9f0-0dad-41f8-bc3f-58e959d2bc91",
   "metadata": {},
   "source": [
    "### 4) Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f07976-7b3e-4509-baea-aecbf123836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_train, y_train, X_test , y_test in zip([X_train],[y_train],[X_test],[y_test]): #la boucle est conservée si jamais on souhaite ajouter un autre dataset tel que pca...\n",
    "\n",
    "    SVM_params  = {\n",
    "    #\"kernel\" : ['rbf'],# 'poly'],#, 'sigmoid'],\n",
    "    #\"degree\" : [3,5],\n",
    "    \"C\": [10.0, 1.0, 0.1],\n",
    "    'class_weight': ['balanced',None]\n",
    "    }\n",
    "\n",
    "    # apply gridsearch model \n",
    "    svm_grid = GridSearchCV(SVC(), SVM_params, scoring = 'accuracy',cv = 4)\n",
    "\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    svm_grid.best_estimator_\n",
    "    y_pred = svm_grid.predict(X_test)\n",
    "\n",
    "    best_score = svm_grid.best_score_\n",
    "    best_params = svm_grid.best_params_\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    print(f'Accuracy =: {round(svm_grid.score(X_train, y_train) * 100, 2)}%')\n",
    "\n",
    "    print(f'Accuracy =: {round(svm_grid.score(X_test, y_test) * 100, 2)}%')\n",
    "\n",
    "    print ('--')\n",
    "    print ('Best Parameters is', best_params)\n",
    "    print ('--')\n",
    "    print ('ROC Score is', roc)\n",
    "    print ('--')\n",
    "    print ('Recall Score is ', recall)\n",
    "    print ('--')\n",
    "    print ('Confusion Matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c5097-91d9-40ff-a384-28f4d92fbe09",
   "metadata": {},
   "source": [
    "### 5) Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c19621-cf41-4951-8d7b-fee84ea54e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_train, y_train, X_test , y_test in zip([X_train],[y_train],[X_test],[y_test]): #la boucle est conservée si jamais on souhaite ajouter un autre dataset tel que pca...\n",
    "\n",
    "    rfc_params  = {\n",
    "    'n_estimators': [500,1000,2000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    \"class_weight\": ['balanced', 'balanced_subsample',None],\n",
    "    #'max_features': ['auto'],\n",
    "    #'random_state': [42]\n",
    "    }\n",
    "\n",
    "    # apply gridsearch model \n",
    "    rfc_grid = GridSearchCV(RandomForestClassifier(), rfc_params, scoring = 'accuracy',cv = 4)\n",
    "\n",
    "    rfc_grid.fit(X_train, y_train)\n",
    "    rfc_grid.best_estimator_\n",
    "    y_pred = rfc_grid.predict(X_test)\n",
    "\n",
    "    best_score = rfc_grid.best_score_\n",
    "    best_params = rfc_grid.best_params_\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    print(f'Accuracy =: {round(rfc_grid.score(X_train, y_train) * 100, 2)}%')\n",
    "\n",
    "    print(f'Accuracy =: {round(rfc_grid.score(X_test, y_test) * 100, 2)}%')\n",
    "\n",
    "    print ('--')\n",
    "    print ('Best Parameters is', best_params)\n",
    "    print ('--')\n",
    "    print ('ROC Score is', roc)\n",
    "    print ('--')\n",
    "    print ('Recall Score is ', recall)\n",
    "    print ('--')\n",
    "    print ('Confusion Matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7259f72-25c2-4578-b4e2-0472a9693428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b5217-babc-46da-8c42-32ab4e6baa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grille de recherche\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab563843-61aa-4881-8895-b714caa9f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856098b-40f9-42d1-bffa-4a4fb826c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485d12b-2221-42bb-ac92-f59d75a78245",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_best = RandomForestClassifier(**grid_search.best_params_)\n",
    "rfc_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090c2a7-9e6b-48e8-acf0-0569f14c22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rfc_best.score(X_test, y_test)\n",
    "print(\"Score de précision : {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d01061-daef-451c-8425-2f54f3a2456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Création et entraînement d'un modèle de forêt aléatoire\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des probabilités des classes pour les données de test\n",
    "probs_rf = rf_clf.predict_proba(X_test)\n",
    "\n",
    "# Calcul des taux de faux positifs, des taux de vrais positifs et des seuils correspondants\n",
    "fpr_rf, tpr_rf, seuils_rf = roc_curve(y_test,probs_rf[:,1],pos_label=1)\n",
    "\n",
    "# Calcul de l'aire sous la courbe ROC\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Tracé de la courbe ROC\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(fpr_rf, tpr_rf, color='green', lw=2, label='Random Forest (auc = %0.2f)' % roc_auc_rf)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Aléatoire (auc = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc15a2a-6c1d-4ac6-af28-cb02d083ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sur les données de test\n",
    "score_rf = rf_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Le score du modèle Random Forest sur les données de test est : {:.2f}\".format(score_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee196ff-f869-411b-abad-f08269de83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Création et entraînement d'un modèle de forêt aléatoire\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des probabilités des classes pour les données de test\n",
    "probs_rf = rf_clf.predict_proba(X_test)\n",
    "\n",
    "# Calcul des taux de faux positifs, des taux de vrais positifs et des seuils correspondants\n",
    "fpr_rf, tpr_rf, seuils_rf = roc_curve(y_test,probs_rf[:,1],pos_label=1)\n",
    "\n",
    "# Calcul de l'aire sous la courbe ROC\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Score sur les données de test\n",
    "score_rf = rf_clf.score(X_test, y_test)\n",
    "\n",
    "# Tracé de la courbe ROC et du score\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(fpr_rf, tpr_rf, color='green', lw=2, label='Random Forest (auc = %0.2f, score = %0.2f)' % (roc_auc_rf, score_rf))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Aléatoire (auc = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux faux positifs')\n",
    "plt.ylabel('Taux vrais positifs')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e930be-ac56-4d70-b563-7cff025b40e4",
   "metadata": {},
   "source": [
    "### 6) K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bfc16-af73-45cf-9656-82a76e630f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_train, y_train, X_test , y_test in zip([X_train],[y_train],[X_test],[y_test]): #la boucle est conservée si jamais on souhaite ajouter un autre dataset tel que pca...\n",
    "\n",
    "    kneig_params  = {\n",
    "    \"n_neighbors\" : [5,10,15,20],\n",
    "    \"weights\" : ['uniform', 'distance'],\n",
    "    #'metric' : ['euclidean', 'minkowski']\n",
    "    }\n",
    "\n",
    "    # apply gridsearch model \n",
    "    kn_grid = GridSearchCV(KNeighborsClassifier(), kneig_params, scoring = 'accuracy',cv = 4)\n",
    "\n",
    "    kn_grid.fit(X_train, y_train)\n",
    "    kn_grid.best_estimator_\n",
    "    y_pred = kn_grid.predict(X_test)\n",
    "\n",
    "    best_score = kn_grid.best_score_\n",
    "    best_params = kn_grid.best_params_\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    print(f'Accuracy =: {round(kn_grid.score(X_train, y_train) * 100, 2)}%')\n",
    "\n",
    "    print(f'Accuracy =: {round(kn_grid.score(X_test, y_test) * 100, 2)}%')\n",
    "\n",
    "    print ('--')\n",
    "    print ('Best Parameters is', best_params)\n",
    "    print ('--')\n",
    "    print ('ROC Score is', roc)\n",
    "    print ('--')\n",
    "    print ('Recall Score is ', recall)\n",
    "    print ('--')\n",
    "    print ('Confusion Matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b81cb-c87c-491f-ba01-a06430396dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf6738-5be9-4841-b99f-61e642e4405d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad060aba-7210-4454-9d24-c2b12562f4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93b270-a611-47a0-914b-8fcbcb54445a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0431b-f5be-41db-b68f-508368356278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea19c6-9be1-456d-99e8-2df4109967cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7699c6-a1ef-4ede-ba0a-8f092c5533bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5592ca7-c78d-4436-ae27-d8690d1adc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "categories = ['No','Yes']\n",
    "\n",
    "\n",
    "sns.heatmap(cm, annot=labels, fmt='',xticklabels=categories,yticklabels=categories)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4dbb3-723f-4206-87fe-8131eb2b5417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_weatherforecast",
   "language": "python",
   "name": "venv_weatherforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
