{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a95bf4-287c-4a59-8366-2b9aae2ce997",
   "metadata": {},
   "source": [
    "## <b>Weather forecast project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa790155-5498-477f-b8f1-a0927a6b0094",
   "metadata": {},
   "source": [
    "# <b>05 - MODEL FOR IMBALANCED DATA    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ddc67-0c72-44df-bdaa-903901c1df7f",
   "metadata": {},
   "source": [
    "### Packages nécessaires au notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0767b5c-b1a4-4c90-b994-d75d7af590ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bokeh\n",
    "import plotly\n",
    "import sys\n",
    "import geopy.distance\n",
    "from collections import defaultdict\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from math import radians\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle\n",
    "import time\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, validation_curve\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression,f_classif,chi2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873eb231-1e7a-4ac7-926f-280fec11afdc",
   "metadata": {},
   "source": [
    "###### <b>Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2f38f4-805a-4f99-93c7-4b8a168afab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_features.csv\").iloc[:,2:] #iloc en attendant de corriger le notebook3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0513c0-9585-4731-a3a7-2a9480cc40b1",
   "metadata": {},
   "source": [
    "###### <b>Séparation des données en variables explicatives et variable cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29f369d-b87c-4ab4-a9b4-bbbeb7bb219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['raintomorrow'],axis=1)\n",
    "y = df['raintomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f08ff75-f595-47e1-8de5-bb48aecfe50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.84\n",
       "1   0.16\n",
       "Name: raintomorrow, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a3d21-6c95-4016-9485-60fdb744674d",
   "metadata": {},
   "source": [
    "> Dans ce dataset, 16% des données correspondent à une prédiction de pluie le lendemain, ce qui signifie qu'un modèle naïf qui prédit qu'il ne pleut pas systématiquement, obtiendrait déjà un score de 84 % d'accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144208b1-8c87-46a0-93d0-e0e5e8f56483",
   "metadata": {},
   "source": [
    "###### <b>Fractionnement des données en ensemble d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b8b8af-76d6-42d0-a470-09fc677bbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438805d8-aa70-44e5-b7fc-656f6587e548",
   "metadata": {},
   "source": [
    "###### <b>Sur-échantillonnage (Oversampling) aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22e95ae9-9304-45f0-bfd1-b13e687dd04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon oversampled : {1: 48841, 0: 48841}\n"
     ]
    }
   ],
   "source": [
    "rOs = RandomOverSampler()\n",
    "X_ro, y_ro = rOs.fit_resample(X_train, y_train)\n",
    "print('Classes échantillon oversampled :', dict(pd.Series(y_ro).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c4920-8631-4023-9341-0d6ac9bc00ad",
   "metadata": {},
   "source": [
    "###### <b>Sous-échantillonnage (Undersampling) aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0fa4ed-c61e-4980-a90b-de1a10f7c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon undersampled : {0: 9324, 1: 9324}\n"
     ]
    }
   ],
   "source": [
    "rUs = RandomUnderSampler()\n",
    "X_ru, y_ru = rUs.fit_resample(X_train, y_train)\n",
    "print('Classes échantillon undersampled :', dict(pd.Series(y_ru).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d90bbc-5e2d-48e3-af28-d1151fa336a9",
   "metadata": {},
   "source": [
    "## 1er modèle : SVM simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb74ed6-6cd1-4f0f-a8a3-3e603bf8e399",
   "metadata": {},
   "source": [
    "#### <b> SVC avec un sur-échantillon aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dad5d95-43bd-4812-bdce-dc91d097aeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0            0     1\n",
      "raintomorrow            \n",
      "0             9570  2670\n",
      "1              633  1669\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.78      0.73      0.85      0.75      0.57     12240\n",
      "          1       0.38      0.73      0.78      0.50      0.75      0.56      2302\n",
      "\n",
      "avg / total       0.85      0.77      0.73      0.80      0.75      0.57     14542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instanciation d'un objet SVM avec une fonction de noyau RBF et gamma='scale'\n",
    "# La fonction de noyau RBF (Radial Basis Function) est une fonction qui peut transformer des données dans un espace de dimension supérieure pour faciliter leur séparation.\n",
    "# gamma est un paramètre de la fonction de noyau RBF. Ici, gamma='scale' signifie que la valeur de gamma sera calculée automatiquement en fonction de la taille de l'échantillon d'entraînement.\n",
    "svm = SVC(gamma='scale')\n",
    "\n",
    "# Entrainement d'un modèle SVM sur les données d'entraînement\n",
    "# La méthode fit() est utilisée pour entraîner le modèle SVM sur les données d'entraînement X_ro et y_ro.\n",
    "svm.fit(X_ro, y_ro)\n",
    "\n",
    "# Prédiction des étiquettes de classe pour les données de test\n",
    "# La méthode predict() est utilisée pour prédire les étiquettes de classe pour les données de test X_test.\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Création d'une table de contingence (matrice de confusion) montrant le nombre de prédictions correctes et incorrectes pour chaque classe\n",
    "# La fonction pd.crosstab() est utilisée pour créer une table de contingence (matrice de confusion) qui montre le nombre de prédictions correctes et incorrectes pour chaque classe.\n",
    "# Les vraies étiquettes de classe y_test et les étiquettes de classe prédites y_pred sont utilisées comme arguments.\n",
    "contingency_table = pd.crosstab(y_test, y_pred)\n",
    "print(contingency_table)\n",
    "\n",
    "# Affichage d'un rapport de classification qui fournit des métriques de performance pour chaque classe\n",
    "# La fonction classification_report_imbalanced() est utilisée pour calculer les métriques de performance pour chaque classe.\n",
    "# Cette fonction est spécifiquement conçue pour les ensembles de données déséquilibrés, où certaines classes ont beaucoup plus d'exemples que d'autres.\n",
    "report = classification_report_imbalanced(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee830510-6d22-49f8-89b2-2f308124a53a",
   "metadata": {},
   "source": [
    "> * En analysant le rapport de classification, nous pouvons conclure que le modèle SVM entraîné sur les données d'entraînement déséquilibrées a une performance moyenne sur les données de test déséquilibrées.\n",
    "> * La métrique de rappel (recall) est relativement élevée pour la classe minoritaire (classe 1), ce qui indique que le modèle est relativement bon à identifier les vrais positifs. \n",
    "> * Cependant, la précision (precision) est relativement faible pour la même classe, ce qui signifie que le modèle peut également produire un grand nombre de faux positifs. \n",
    "> * La métrique F1-score est une mesure harmonique entre la précision et le rappel et est donc une mesure plus équilibrée de la performance globale du modèle. \n",
    "> * Dans ce cas, le score F1 est d'environ 0,5 pour la classe 1 minoritaire. \n",
    "> * Cela indique que le modèle peut être amélioré pour mieux identifier les exemples de la classe minoritaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c5204-fd16-4828-9480-5ba3c008fcea",
   "metadata": {},
   "source": [
    "#### <b> SVC avec un sous-échantillon aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d130e08f-ea70-48ad-a98f-46e5627317ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0            0     1\n",
      "raintomorrow            \n",
      "0             9130  3110\n",
      "1              633  1669\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.75      0.73      0.83      0.74      0.54     12240\n",
      "          1       0.35      0.73      0.75      0.47      0.74      0.54      2302\n",
      "\n",
      "avg / total       0.84      0.74      0.73      0.77      0.74      0.54     14542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_ru, y_ru)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(pd.crosstab(y_test, y_pred))\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6513bb2-9bc6-4d67-866b-50286481c016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0            0     1\n",
      "raintomorrow            \n",
      "0             9130  3110\n",
      "1              633  1669\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.75      0.73      0.83      0.74      0.54     12240\n",
      "          1       0.35      0.73      0.75      0.47      0.74      0.54      2302\n",
      "\n",
      "avg / total       0.84      0.74      0.73      0.77      0.74      0.54     14542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instanciation d'un objet SVC avec le paramètre gamma défini sur \"scale\"\n",
    "svm = SVC(gamma='scale')\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement équilibrées (X_ru et y_ru) à l'aide de la méthode fit()\n",
    "svm.fit(X_ru, y_ru)\n",
    "\n",
    "# Prédiction des étiquettes de classe pour les données de test à l'aide de la méthode predict()\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Création de la matrice de confusion à partir des étiquettes de classe prédites et des étiquettes de classe réelles en utilisant la fonction crosstab() de pandas\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred)\n",
    "\n",
    "# Affichage de la matrice de confusion à l'aide de la fonction print()\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Calcul et affichage du rapport de classification équilibré à l'aide de la fonction classification_report_imbalanced()\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70b8f4-29d9-418c-8c62-362a8a6eb9eb",
   "metadata": {},
   "source": [
    "> * Le modèle SVM a des performances relativement bonnes pour prédire la classe \"0\" (pas de pluie demain), mais des performances plus faibles pour prédire la classe \"1\" (pluie demain).\n",
    "> * Le modèle a correctement prédit la classe \"0\" pour la grande majorité des échantillons (9130 sur 12240, soit une précision de 0.94), mais il a eu plus de difficulté à prédire la classe \"1\" (seulement 1669 prédictions correctes sur 2302, soit une précision de 0.35).\n",
    "> * Le score F1 global est de 0.77, ce qui indique une performance globale moyenne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76081e8d-7f8f-4a07-9019-fc7d4eb85d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raintomorrow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9480</td>\n",
       "      <td>2760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>639</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0     1\n",
       "raintomorrow            \n",
       "0             9480  2760\n",
       "1              639  1663"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(gamma='scale', class_weight='balanced')\n",
    "svm.fit(X_train, y_train)                         \n",
    "\n",
    "preds = svm.predict(X_test)\n",
    "\n",
    "pd.crosstab(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31eb06f5-2ff2-44a9-9b17-4659cf6b236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.75      0.73      0.83      0.74      0.54     12240\n",
      "          1       0.35      0.73      0.75      0.47      0.74      0.54      2302\n",
      "\n",
      "avg / total       0.84      0.74      0.73      0.77      0.74      0.54     14542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(probability=True, gamma='scale') # 'probability= True' est nécessaire pour retourner les probas\n",
    "svm.fit(X_train, y_train)                        # mais ralentit l'entraînement\n",
    "\n",
    "threshold = 0.4 # Tester avec 0.4, 0.6, ...\n",
    "\n",
    "probs = svm.predict_proba(X_test)\n",
    "pred_class = (probs[:,1]>=threshold).astype('int')\n",
    "\n",
    "pd.crosstab(y_test, pred_class)\n",
    "\n",
    "# Calcul et affichage du rapport de classification équilibré à l'aide de la fonction classification_report_imbalanced()\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1ef6af7-c040-4ef2-80d2-460371cdbf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.75      0.73      0.83      0.74      0.54     12240\n",
      "          1       0.35      0.73      0.75      0.47      0.74      0.54      2302\n",
      "\n",
      "avg / total       0.84      0.74      0.73      0.77      0.74      0.54     14542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcul et affichage du rapport de classification équilibré à l'aide de la fonction classification_report_imbalanced()\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc6e73-47eb-4edf-999c-9631c5c06190",
   "metadata": {},
   "source": [
    "* Precision (précision): C'est la proportion d'observations prédites comme positives (1) qui sont réellement positives. Pour la classe 0, la précision est de 0,94, ce qui signifie que 94% des observations prédites comme positives (pas de pluie demain) étaient correctes, tandis que pour la classe 1, la précision est de 0,35, ce qui indique que seulement 35% des observations prédites comme positives (pluie demain) étaient correctes.\n",
    "\n",
    "* Recall (rappel): C'est la proportion d'observations réellement positives qui ont été correctement identifiées par le modèle. Pour la classe 0, le rappel est de 0,75, ce qui signifie que le modèle a correctement identifié 75% des observations de pluie, tandis que pour la classe 1, le rappel est de 0,73, ce qui signifie que le modèle a correctement identifié 73% des observations de pas de pluie.\n",
    "\n",
    "* Specificity (spécificité): C'est la proportion d'observations réellement négatives qui ont été correctement identifiées par le modèle. Pour la classe 0, la spécificité est de 0,73, ce qui signifie que le modèle a correctement identifié 73% des observations de pas de pluie, tandis que pour la classe 1, la spécificité est également de 0,75, ce qui signifie que le modèle a correctement identifié 75% des observations de pluie.\n",
    "\n",
    "* F1-score: C'est une moyenne pondérée de la précision et du rappel, qui combine les deux métriques en une seule. Pour la classe 0, le score F1 est de 0,83, tandis que pour la classe 1, le score F1 est de 0,47.\n",
    "\n",
    "* Geometric mean (moyenne géométrique): C'est la racine carrée du produit des taux de vrais positifs et de vrais négatifs, qui donne une mesure de la performance globale du modèle. Pour les deux classes, la moyenne géométrique est de 0,74.\n",
    "\n",
    "* Balanced accuracy (exactitude équilibrée): C'est la moyenne arithmétique du rappel et de la spécificité, qui est une mesure de la précision globale du modèle pour les deux classes. Pour les deux classes, l'exactitude équilibrée est de 0,74.\n",
    "\n",
    "Le rapport de classification équilibré montre que le modèle a une précision élevée pour la classe 0 (pas de pluie demain), mais une précision beaucoup plus faible pour la classe 1 (pluie demain). Le rappel est similaire pour les deux classes, mais la spécificité est légèrement plus élevée pour la classe 1. Le score F1 est plus élevé pour la classe 0 que pour la classe 1. La moyenne géométrique et l'exactitude équilibrée sont similaires pour les deux classes et indiquent une performance globale moyenne du modèle. Cela suggère que le modèle a plus de difficulté à prédire les jours avec pluie que les jours sans pluie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7743fe0-7080-4654-80a8-df41b67e2011",
   "metadata": {},
   "source": [
    "#### <b>  Modification de la valeur de seuil de la classe 1 (pluie demain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73d5df37-5931-4e86-a46e-dd15c35a01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0             0     1\n",
      "raintomorrow             \n",
      "0             10969  1271\n",
      "1               969  1333\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.90      0.58      0.91      0.72      0.54     12240\n",
      "          1       0.51      0.58      0.90      0.54      0.72      0.50      2302\n",
      "\n",
      "avg / total       0.85      0.85      0.63      0.85      0.72      0.53     14542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Définition d'un seuil de décision pour la prédiction\n",
    "threshold = 0.3 # Tester avec 0.4, 0.6, ...\n",
    "\n",
    "# Prédiction des probabilités de chaque classe pour les données de test à l'aide du modèle SVM\n",
    "probs = svm.predict_proba(X_test)\n",
    "\n",
    "# Sélection de la classe prédite en fonction du seuil de décision\n",
    "pred_class = (probs[:,1]>=threshold).astype('int')\n",
    "\n",
    "# Affichage d'une matrice de confusion pour comparer les résultats de la prédiction avec les vraies étiquettes\n",
    "print(pd.crosstab(y_test, pred_class))\n",
    "\n",
    "# Affichage du rapport de classification qui fournit des mesures de performance pour chaque classe, y compris pour les classes déséquilibrées\n",
    "print(classification_report_imbalanced(y_test, pred_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e0f62-0ca5-4718-8fa7-9401404612f7",
   "metadata": {},
   "source": [
    "* Pour la classe 0, le modèle a une précision de 92%, ce qui signifie que lorsque le modèle prédit qu'il ne pleuvra pas, il a raison 92% du temps. Le rappel pour la classe 0 est de 90%, ce qui signifie que le modèle identifie correctement 90% des cas où il ne pleut pas. Le score F1 pour la classe 0 est de 91%, ce qui est une moyenne pondérée de la précision et du rappel. La spécificité pour la classe 0 est faible, à seulement 58%, ce qui signifie que le modèle a tendance à prédire des faux positifs (prédire qu'il va pleuvoir quand il ne pleut pas).\n",
    "\n",
    "* Pour la classe 1, le modèle a une précision de 51%, ce qui signifie que lorsque le modèle prédit qu'il pleuvra, il a raison seulement 51% du temps. Le rappel pour la classe 1 est de 58%, ce qui signifie que le modèle identifie correctement seulement 58% des cas où il pleuvra. Le score F1 pour la classe 1 est de 54%, ce qui est une moyenne pondérée de la précision et du rappel. La spécificité pour la classe 1 est élevée, à 90%, ce qui signifie que le modèle a tendance à prédire des faux négatifs (prédire qu'il ne va pas pleuvoir quand il pleuvra).\n",
    "\n",
    "* En général, les performances du modèle sont moyennes à bonnes pour la classe 0, mais médiocres pour la classe 1. Cela indique que le modèle a du mal à prédire les cas où il pleuvra, ce qui peut être problématique dans des situations où cette prédiction est cruciale. Les performances du modèle pourraient être améliorées en ajustant les paramètres du modèle, en utilisant des techniques de prétraitement de données ou en utilisant un algorithme de classification différent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468137a-57f5-44e3-bf20-1de33a124a4d",
   "metadata": {},
   "source": [
    "## 2ième modèle : BalancedRandomForestClassifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3def6802-6963-4aeb-8380-e7c7a66b2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0            0     1\n",
      "raintomorrow            \n",
      "0             9702  2538\n",
      "1              423  1879\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.96      0.79      0.82      0.87      0.80      0.65     12240\n",
      "          1       0.43      0.82      0.79      0.56      0.80      0.65      2302\n",
      "\n",
      "avg / total       0.87      0.80      0.81      0.82      0.80      0.65     14542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Création d'une instance de la classe BalancedRandomForestClassifier\n",
    "bclf = BalancedRandomForestClassifier()\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "bclf.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des étiquettes de classe pour les données de test en utilisant le modèle entraîné\n",
    "y_pred = bclf.predict(X_test)\n",
    "\n",
    "# Affichage de la table de contingence (matrice de confusion) pour évaluer la performance du modèle\n",
    "print(pd.crosstab(y_test, y_pred))\n",
    "\n",
    "# Importation de la fonction classification_report_imbalanced pour afficher le rapport de classification déséquilibré\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# Affichage du rapport de classification qui fournit des mesures de performance pour chaque classe, y compris pour les classes déséquilibrées\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03803ad6-7e30-4249-a99f-8e0fb3e545e7",
   "metadata": {},
   "source": [
    "* Dans cette analyse de résultats, nous avons utilisé le modèle BalancedRandomForestClassifier pour prédire les étiquettes de classe pour les données de test. \n",
    "La table de contingence (matrice de confusion) montre que le modèle a prédit correctement 9702 observations de la classe 0 (pas de pluie demain) et 1879 observations de la classe 1 (pluie demain), tandis que 423 observations de la classe 1 ont été mal classées en classe 0 et 2538 observations de la classe 0 ont été mal classées en classe 1.\n",
    "\n",
    "* Le rapport de classification déséquilibré montre que le modèle a une précision élevée pour la classe 0 (96%) et une précision faible pour la classe 1 (43%). Cela signifie que le modèle est très précis pour prédire les observations de la classe 0, mais qu'il a tendance à faire plus d'erreurs pour prédire les observations de la classe 1. Le rappel est élevé pour la classe 1 (82%), ce qui indique que le modèle a identifié la plupart des observations de la classe 1, mais le rappel est faible pour la classe 0 (79%), ce qui indique que le modèle a manqué certaines observations de la classe 0. Le score F1 est de 0,56 pour la classe 1, ce qui signifie que le modèle a un compromis entre la précision et le rappel pour cette classe.\n",
    "\n",
    "* En fin de compte, le modèle BalancedRandomForestClassifier semble mieux performant que le modèle SVM dans la prédiction de la classe déséquilibrée. Cependant, le modèle a encore besoin d'être amélioré pour être plus performant pour la classe 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_weatherforecast",
   "language": "python",
   "name": "venv_weatherforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
